* fork()
  Unix/Linux 操作系统提供了一个 fork()系统调用，它非常特殊。
  普通的函数调用，调用一次，返回一次，但是 fork()调用一次，返回两次，因为操作系统自动把当前进程（称为父进程）复制了一份（称为子进程），然后，分别在父进程和子进程内返回。

  子进程永远返回 0，而父进程返回子进程的 ID。
  这样做的理由是，一个父进程可以 fork 出很多子进程，所以，父进程要记下每个子进程的 ID，而子进程只需要调用 getppid()就可以拿到父进程的 ID。

* 文件描述符(File descriptor)
  文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表, 该表称为描述符表(descriptor table)。
  当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。
  在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。
  但是文件描述符这一概念往往只适用于 UNIX、Linux 这样的操作系统。

* inode(索引节点)
** 简介
  文件储存在硬盘上, 硬盘的最小存储单位叫做扇区(Sector, 0.5KB), 多个扇区组成块(Block, 一般为 4k).
  操作系统以块为单由于存储介质的特性，磁盘本身存取就比主存慢很多，再加上机械运动耗费，磁盘的存取速度往往是主存的几百分分之一，因此为了提高效率，要尽量减少磁盘 I/O。为了达到这个目的，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。这样做的理论依据是计算机科学中著名的局部性原理：

位读取硬盘.

  一个文件使用一个 inode(索引节点), inode 中记录文件的元信息. 
  inode 的数目和本身的大小在格式化时指定, 因此文件系统所能建立的文件数目是有限制的.
  
  inode 包含:
  + inode 编号
  + 文件类型
  + 文件的字节数
  + 拥有者的 Group ID
  + 文件的 Group ID
  + 读写权限
  + 时间戳, 一个三个
    + ctime, 指 inode 上一次变动的时间.
    + mtime, 指文件内容上一次变动的时间.
    + atime, 指文件上一次打开的时间.
    + 链接数, 有多少个文件名指向这个 inode(硬链接的数量)
  + 文件 block 的位置.

  用户通过文件名，打开文件。实际上，系统内部这个过程分成三步：
  1. 首先，系统找到这个文件名对应的 inode 号码；
  2. 其次，通过 inode 号码，获取 inode 信息；
  3. 最后，根据 inode 信息，找到文件数据所在的 block，读出数据。

  文件名与 inode 的映射关系实际上是保存在目录项中，目录（directory）也是一种文件，
  文件内容是该目录下的文件名以及该文件名对应的 inode 号码。

** 硬链接和软链接
   硬链接源文件与目标文件的 inode 号码相同，都指向同一个 inode。inode 信息中有一项叫做”链接数”，记录指向该 inode 的文件名总数，这时就会增加 1。
   删除一个文件名，就会使得 inode 节点中的”链接数”减 1。当这个值减到 0，表明没有文件名指向这个 inode，系统就会回收这个 inode 号码，以及其所对应 block 区域。 
   软链接源文件的内容是目标文件的路径。读取软连接文件时，系统会自动将访问者导向目标文件。如果删除了目标文件，打开软连接文件时就会报错：”No such file or directory”。



* linux 进程数据结构: task_struct

#+BEGIN_SRC c

  struct task_struct
  {
    /*
      1. state: 进程执行时，它会根据具体情况改变状态。进程状态是进程调度和对换的依据。Linux 中的进程主要有如下状态:
      1) TASK_RUNNING: 可运行
      处于这种状态的进程，只有两种状态:
      1.1) 正在运行
      正在运行的进程就是当前进程(由 current 所指向的进程)
      1.2) 正准备运行
      准备运行的进程只要得到 CPU 就可以立即投入运行，CPU 是这些进程唯一等待的系统资源，系统中有一个运行队列(run_queue)，
      用来容纳所有处于可运行状态的进程，调度程序执行时，从中选择一个进程投入运行

      2) TASK_INTERRUPTIBLE: 可中断的等待状态，是针对等待某事件或其他资源的睡眠进程设置的，
      在内核发送信号给该进程表明事件已经发生时，进程状态变为 TASK_RUNNING，它只要调度器选中该进程即可恢复执行

      3) TASK_UNINTERRUPTIBLE: 不可中断的等待状态
      处于该状态的进程正在等待某个事件(event)或某个资源，它肯定位于系统中的某个等待队列(wait_queue)中，
      处于不可中断等待态的进程是因为硬件环境不能满足而等待，例如等待特定的系统资源，它任何情况下都不能被打断，
      只能用特定的方式来唤醒它，例如唤醒函数 wake_up()等,它们不能由外部信号唤醒，只能由内核亲自唤醒

      4) TASK_ZOMBIE: 僵死
      进程虽然已经终止，但由于某种原因，父进程还没有执行 wait()系统调用，终止进程的信息也还没有回收。
      顾名思义，处于该状态的进程就是死进程，这种进程实际上是系统中的垃圾，必须进行相应处理以释放其占用的资源。

      5) TASK_STOPPED: 暂停
      此时的进程暂时停止运行来接受某种特殊处理。通常当进程接收到 SIGSTOP、SIGTSTP、SIGTTIN 或 SIGTTOU 信号后就处于这种状态。
      例如，正接受调试的进程就处于这种状态
      　　　　
      　　　　　6) TASK_TRACED
      　　　　　从本质上来说，这属于 TASK_STOPPED 状态，用于从停止的进程中，将当前被调试的进程与常规的进程区分开来
      　　　　　　
      　　　　　7) TASK_DEAD
      　　　　　父进程 wait 系统调用发出后，当子进程退出时，父进程负责回收子进程的全部资源，子进程进入 TASK_DEAD 状态

      8) TASK_SWAPPING: 换入/换出
    ,*/
    volatile long state;

    /*
      2. stack
      进程内核栈，进程通过 alloc_thread_info 函数分配它的内核栈，通过 free_thread_info 函数释放所分配的内核栈
    ,*/
    void *stack;

    /*
      3. usage
      进程描述符使用计数，被置为 2 时，表示进程描述符正在被使用而且其相应的进程处于活动状态
      */
      atomic_t usage;

    /*
      4. flags
      flags 是进程当前的状态标志(注意和运行状态区分)
      1) #define PF_ALIGNWARN    0x00000001: 显示内存地址未对齐警告
      2) #define PF_PTRACED    0x00000010: 标识是否是否调用了 ptrace
      3) #define PF_TRACESYS    0x00000020: 跟踪系统调用
      4) #define PF_FORKNOEXEC 0x00000040: 已经完成 fork，但还没有调用 exec
      5) #define PF_SUPERPRIV    0x00000100: 使用超级用户(root)权限
      6) #define PF_DUMPCORE    0x00000200: dumped core
      7) #define PF_SIGNALED    0x00000400: 此进程由于其他进程发送相关信号而被杀死
      8) #define PF_STARTING    0x00000002: 当前进程正在被创建
      9) #define PF_EXITING    0x00000004: 当前进程正在关闭
      10) #define PF_USEDFPU    0x00100000: Process used the FPU this quantum(SMP only)
      #define PF_DTRACE    0x00200000: delayed trace (used on m68k)
    ,*/
    unsigned int flags;

    /*
      5. ptrace
      ptrace 系统调用，成员 ptrace 被设置为 0 时表示不需要被跟踪，它的可能取值如下：
      linux-2.6.38.8/include/linux/ptrace.h
      1) #define PT_PTRACED    0x00000001
      2) #define PT_DTRACE    0x00000002: delayed trace (used on m68k, i386)
      3) #define PT_TRACESYSGOOD    0x00000004
      4) #define PT_PTRACE_CAP    0x00000008: ptracer can follow suid-exec
      5) #define PT_TRACE_FORK    0x00000010
      6) #define PT_TRACE_VFORK    0x00000020
      7) #define PT_TRACE_CLONE    0x00000040
      8) #define PT_TRACE_EXEC    0x00000080
      9) #define PT_TRACE_VFORK_DONE    0x00000100
      10) #define PT_TRACE_EXIT    0x00000200
    ,*/
    unsigned int ptrace;
    unsigned long ptrace_message;
    siginfo_t *last_siginfo;

    /*
      6. lock_depth
      用于表示获取大内核锁的次数，如果进程未获得过锁，则置为-1
    ,*/
    int lock_depth;

    /*
      7. oncpu
      在 SMP 上帮助实现无加锁的进程切换(unlocked context switches)
    ,*/
  #ifdef CONFIG_SMP
  #ifdef __ARCH_WANT_UNLOCKED_CTXSW
    int oncpu;
  #endif
  #endif

    /*
      8. 进程调度
      1) prio: 调度器考虑的优先级保存在 prio，由于在某些情况下内核需要暂时提高进程的优先级，因此需要第三个成员来表示(除了 static_prio、normal_prio 之外)，由于这些改变不是持久的，因此静态(static_prio)和普通(normal_prio)优先级不受影响
      2) static_prio: 用于保存进程的"静态优先级"，静态优先级是进程"启动"时分配的优先级，它可以用 nice、sched_setscheduler 系统调用修改，否则在进程运行期间会一直保持恒定
      3) normal_prio: 表示基于进程的"静态优先级"和"调度策略"计算出的优先级，因此，即使普通进程和实时进程具有相同的静态优先级(static_prio)，其普通优先级(normal_prio)也是不同的。进程分支时(fork)，新创建的子进程会集成普通优先级
    ,*/
    int prio, static_prio, normal_prio;
    /*
      4) rt_priority: 表示实时进程的优先级，需要明白的是，"实时进程优先级"和"普通进程优先级"有两个独立的范畴，实时进程即使是最低优先级也高于普通进程，最低的实时优先级为 0，最高的优先级为 99，值越大，表明优先级越高
    ,*/
    unsigned int rt_priority;
    /*
      5) sched_class: 该进程所属的调度类，目前内核中有实现以下四种：
      5.1) static const struct sched_class fair_sched_class;
      5.2) static const struct sched_class rt_sched_class;
      5.3) static const struct sched_class idle_sched_class;
      5.4) static const struct sched_class stop_sched_class;
    ,*/
    const struct sched_class *sched_class;
    /*
      6) se: 用于普通进程的调用实体
      　　调度器不限于调度进程，还可以处理更大的实体，这可以实现"组调度"，可用的 CPU 时间可以首先在一般的进程组(例如所有进程可以按所有者分组)之间分配，接下来分配的时间在组内再次分配
      　　这种一般性要求调度器不直接操作进程，而是处理"可调度实体"，一个实体有 sched_entity 的一个实例标识
      　　在最简单的情况下，调度在各个进程上执行，由于调度器设计为处理可调度的实体，在调度器看来各个进程也必须也像这样的实体，因此 se 在 task_struct 中内嵌了一个 sched_entity 实例，调度器可据此操作各个 task_struct
    ,*/
    struct sched_entity se;
    /*
      7) rt: 用于实时进程的调用实体
    ,*/
    struct sched_rt_entity rt;

  #ifdef CONFIG_PREEMPT_NOTIFIERS
    /*
      9. preempt_notifier
      preempt_notifiers 结构体链表
    ,*/
    struct hlist_head preempt_notifiers;
  #endif

    /*
      10. fpu_counter
      FPU 使用计数
    ,*/
    unsigned char fpu_counter;

  #ifdef CONFIG_BLK_DEV_IO_TRACE
    /*
      11. btrace_seq
      blktrace 是一个针对 Linux 内核中块设备 I/O 层的跟踪工具
    ,*/
    unsigned int btrace_seq;
  #endif

    /*
      12. policy
      policy 表示进程的调度策略，目前主要有以下五种：
      1) #define SCHED_NORMAL        0: 用于普通进程，它们通过完全公平调度器来处理
      2) #define SCHED_FIFO        1: 先来先服务调度，由实时调度类处理
      3) #define SCHED_RR            2: 时间片轮转调度，由实时调度类处理
      4) #define SCHED_BATCH        3: 用于非交互、CPU 使用密集的批处理进程，通过完全公平调度器来处理，调度决策对此类进程给与"冷处理"，它们绝不会抢占 CFS 调度器处理的另一个进程，因此不会干扰交互式进程，如果不打算用 nice 降低进程的静态优先级，同时又不希望该进程影响系统的交互性，最适合用该调度策略
      5) #define SCHED_IDLE        5: 可用于次要的进程，其相对权重总是最小的，也通过完全公平调度器来处理。要注意的是，SCHED_IDLE 不负责调度空闲进程，空闲进程由内核提供单独的机制来处理
      只有 root 用户能通过 sched_setscheduler()系统调用来改变调度策略
    ,*/
    unsigned int policy;

    /*
      13. cpus_allowed
      cpus_allowed 是一个位域，在多处理器系统上使用，用于控制进程可以在哪里处理器上运行
    ,*/
    cpumask_t cpus_allowed;

    /*
      14. RCU 同步原语
    ,*/
  #ifdef CONFIG_TREE_PREEMPT_RCU
    int rcu_read_lock_nesting;
    char rcu_read_unlock_special;
    struct rcu_node *rcu_blocked_node;
    struct list_head rcu_node_entry;
  #endif /* #ifdef CONFIG_TREE_PREEMPT_RCU */

  #if defined(CONFIG_SCHEDSTATS) || defined(CONFIG_TASK_DELAY_ACCT)
    /*
      15. sched_info
      用于调度器统计进程的运行信息
    ,*/
    struct sched_info sched_info;
  #endif

    /*
      16. tasks
      通过 list_head 将当前进程的 task_struct 串联进内核的进程列表中，构建；linux 进程链表
    ,*/
    struct list_head tasks;

    /*
      17. pushable_tasks
      limit pushing to one attempt
    ,*/
    struct plist_node pushable_tasks;

    /*
      18. 进程地址空间
      1) mm: 指向进程所拥有的内存描述符
      2) active_mm: active_mm 指向进程运行时所使用的内存描述符
      对于普通进程而言，这两个指针变量的值相同。但是，内核线程不拥有任何内存描述符，所以它们的 mm 成员总是为 NULL。当内核线程得以运行时，它的 active_mm 成员被初始化为前一个运行进程的 active_mm 值
    ,*/
    struct mm_struct *mm, *active_mm;

    /*
      19. exit_state
      进程退出状态码
    ,*/
    int exit_state;

    /*
      20. 判断标志
      1) exit_code
      exit_code 用于设置进程的终止代号，这个值要么是_exit()或 exit_group()系统调用参数(正常终止)，
      要么是由内核提供的一个错误代号(异常终止)
      2) exit_signal
      exit_signal 被置为-1 时表示是某个线程组中的一员。只有当线程组的最后一个成员终止时，才会产生一个信号，
      以通知线程组的领头进程的父进程
    ,*/
    int exit_code, exit_signal;
    /*
      3) pdeath_signal
      pdeath_signal 用于判断父进程终止时发送信号
    ,*/
    int pdeath_signal;
    /*
      4)  personality 用于处理不同的 ABI，它的可能取值如下：
      enum
      {
      PER_LINUX =        0x0000,
      PER_LINUX_32BIT =    0x0000 | ADDR_LIMIT_32BIT,
      PER_LINUX_FDPIC =    0x0000 | FDPIC_FUNCPTRS,
      PER_SVR4 =        0x0001 | STICKY_TIMEOUTS | MMAP_PAGE_ZERO,
      PER_SVR3 =        0x0002 | STICKY_TIMEOUTS | SHORT_INODE,
      PER_SCOSVR3 =        0x0003 | STICKY_TIMEOUTS |
      WHOLE_SECONDS | SHORT_INODE,
      PER_OSR5 =        0x0003 | STICKY_TIMEOUTS | WHOLE_SECONDS,
      PER_WYSEV386 =        0x0004 | STICKY_TIMEOUTS | SHORT_INODE,
      PER_ISCR4 =        0x0005 | STICKY_TIMEOUTS,
      PER_BSD =        0x0006,
      PER_SUNOS =        0x0006 | STICKY_TIMEOUTS,
      PER_XENIX =        0x0007 | STICKY_TIMEOUTS | SHORT_INODE,
      PER_LINUX32 =        0x0008,
      PER_LINUX32_3GB =    0x0008 | ADDR_LIMIT_3GB,
      PER_IRIX32 =        0x0009 | STICKY_TIMEOUTS,
      PER_IRIXN32 =        0x000a | STICKY_TIMEOUTS,
      PER_IRIX64 =        0x000b | STICKY_TIMEOUTS,
      PER_RISCOS =        0x000c,
      PER_SOLARIS =        0x000d | STICKY_TIMEOUTS,
      PER_UW7 =        0x000e | STICKY_TIMEOUTS | MMAP_PAGE_ZERO,
      PER_OSF4 =        0x000f,
      PER_HPUX =        0x0010,
      PER_MASK =        0x00ff,
      };
    ,*/
    unsigned int personality;
    /*
      5) did_exec
      did_exec 用于记录进程代码是否被 execve()函数所执行
    ,*/
    unsigned did_exec:1;
    /*
      6) in_execve
      in_execve 用于通知 LSM 是否被 do_execve()函数所调用
    ,*/
    unsigned in_execve:1;
    /*
      7) in_iowait
      in_iowait 用于判断是否进行 iowait 计数
    ,*/
    unsigned in_iowait:1;

    /*
      8) sched_reset_on_fork
      sched_reset_on_fork 用于判断是否恢复默认的优先级或调度策略
    ,*/
    unsigned sched_reset_on_fork:1;

    /*
      21. 进程标识符(PID)
      在 CONFIG_BASE_SMALL 配置为 0 的情况下，PID 的取值范围是 0 到 32767，即系统中的进程数最大为 32768 个
      #define PID_MAX_DEFAULT (CONFIG_BASE_SMALL ? 0x1000 : 0x8000)
      在 Linux 系统中，一个线程组中的所有线程使用和该线程组的领头线程(该组中的第一个轻量级进程)相同的 PID，并被存放在 tgid 成员中。
      只有线程组的领头线程的 pid 成员才会被设置为与 tgid 相同的值。注意，getpid()系统调用
      返回的是当前进程的 tgid 值而不是 pid 值。
    ,*/
    pid_t pid;
    pid_t tgid;

  #ifdef CONFIG_CC_STACKPROTECTOR
    /*
      22. stack_canary
      防止内核堆栈溢出，在 GCC 编译内核时，需要加上-fstack-protector 选项
    ,*/
    unsigned long stack_canary;
  #endif

    /*
      23. 表示进程亲属关系的成员
      1) real_parent: 指向其父进程，如果创建它的父进程不再存在，则指向 PID 为 1 的 init 进程
      2) parent: 指向其父进程，当它终止时，必须向它的父进程发送信号。它的值通常与 real_parent 相同
    ,*/
    struct task_struct *real_parent;
    struct task_struct *parent;
    /*
      3) children: 表示链表的头部，链表中的所有元素都是它的子进程(子进程链表)
      4) sibling: 用于把当前进程插入到兄弟链表中(连接到父进程的子进程链表(兄弟链表))
      5) group_leader: 指向其所在进程组的领头进程
    ,*/
    struct list_head children;
    struct list_head sibling;
    struct task_struct *group_leader;

    struct list_head ptraced;
    struct list_head ptrace_entry;
    struct bts_context *bts;

    /*
      24. pids
      PID 散列表和链表
    ,*/
    struct pid_link pids[PIDTYPE_MAX];
    /*
      25. thread_group
      线程组中所有进程的链表
    ,*/
    struct list_head thread_group;

    /*
      26. do_fork 函数
      1) vfork_done
      在执行 do_fork()时，如果给定特别标志，则 vfork_done 会指向一个特殊地址
      2) set_child_tid、clear_child_tid
      如果 copy_process 函数的 clone_flags 参数的值被置为 CLONE_CHILD_SETTID 或 CLONE_CHILD_CLEARTID，则会把 child_tidptr 参数的值分别复制到 set_child_tid 和 clear_child_tid 成员。这些标志说明必须改变子
      进程用户态地址空间的 child_tidptr 所指向的变量的值。
    ,*/
    struct completion *vfork_done;
    int __user *set_child_tid;
    int __user *clear_child_tid;

    /*
      27. 记录进程的 I/O 计数(时间)
      1) utime
      用于记录进程在"用户态"下所经过的节拍数(定时器)
      2) stime
      用于记录进程在"内核态"下所经过的节拍数(定时器)
      3) utimescaled
      用于记录进程在"用户态"的运行时间，但它们以处理器的频率为刻度
      4) stimescaled
      用于记录进程在"内核态"的运行时间，但它们以处理器的频率为刻度
    ,*/
    cputime_t utime, stime, utimescaled, stimescaled;
    /*
      5) gtime
      以节拍计数的虚拟机运行时间(guest time)
    ,*/
    cputime_t gtime;
    /*
      6) prev_utime、prev_stime 是先前的运行时间
    ,*/
    cputime_t prev_utime, prev_stime;
    /*
      7) nvcsw
      自愿(voluntary)上下文切换计数
      8) nivcsw
      非自愿(involuntary)上下文切换计数
    ,*/
    unsigned long nvcsw, nivcsw;
    /*
      9) start_time
      进程创建时间
      10) real_start_time
      进程睡眠时间，还包含了进程睡眠时间，常用于/proc/pid/stat，
    ,*/
    struct timespec start_time;
    struct timespec real_start_time;
    /*
      11) cputime_expires
      用来统计进程或进程组被跟踪的处理器时间，其中的三个成员对应着 cpu_timers[3]的三个链表
    ,*/
    struct task_cputime cputime_expires;
    struct list_head cpu_timers[3];
  #ifdef CONFIG_DETECT_HUNG_TASK
    /*
      12) last_switch_count
      nvcsw 和 nivcsw 的总和
    ,*/
    unsigned long last_switch_count;
  #endif
    struct task_io_accounting ioac;
  #if defined(CONFIG_TASK_XACCT)
    u64 acct_rss_mem1;
    u64 acct_vm_mem1;
    cputime_t acct_timexpd;
  #endif

    /*
      28. 缺页统计
    ,*/
    unsigned long min_flt, maj_flt;

    /*
      29. 进程权能
    ,*/
    const struct cred *real_cred;
    const struct cred *cred;
    struct mutex cred_guard_mutex;
    struct cred *replacement_session_keyring;

    /*
      30. comm[TASK_COMM_LEN]
      相应的程序名
    ,*/
    char comm[TASK_COMM_LEN];

    /*
      31. 文件
      1) fs
      用来表示进程与文件系统的联系，包括当前目录和根目录
      2) files
      表示进程当前打开的文件
    ,*/
    int link_count, total_link_count;
    struct fs_struct *fs;
    struct files_struct *files;

  #ifdef CONFIG_SYSVIPC
    /*
      32. sysvsem
      进程通信(SYSVIPC)
    ,*/
    struct sysv_sem sysvsem;
  #endif

    /*
      33. 处理器特有数据
    ,*/
    struct thread_struct thread;

    /*
      34. nsproxy
      命名空间
    ,*/
    struct nsproxy *nsproxy;

    /*
      35. 信号处理
      1) signal: 指向进程的信号描述符
      2) sighand: 指向进程的信号处理程序描述符
    ,*/
    struct signal_struct *signal;
    struct sighand_struct *sighand;
    /*
      3) blocked: 表示被阻塞信号的掩码
      4) real_blocked: 表示临时掩码
    ,*/
    sigset_t blocked, real_blocked;
    sigset_t saved_sigmask;
    /*
      5) pending: 存放私有挂起信号的数据结构
    ,*/
    struct sigpending pending;
    /*
      6) sas_ss_sp: 信号处理程序备用堆栈的地址
      7) sas_ss_size: 表示堆栈的大小
    ,*/
    unsigned long sas_ss_sp;
    size_t sas_ss_size;
    /*
      8) notifier
      设备驱动程序常用 notifier 指向的函数来阻塞进程的某些信号
      9) otifier_data
      指的是 notifier 所指向的函数可能使用的数据。
      10) otifier_mask
      标识这些信号的位掩码
    ,*/
    int (*notifier)(void *priv);
    void *notifier_data;
    sigset_t *notifier_mask;

    /*
      36. 进程审计
    ,*/
    struct audit_context *audit_context;
  #ifdef CONFIG_AUDITSYSCALL
    uid_t loginuid;
    unsigned int sessionid;
  #endif

    /*
      37. secure computing
    ,*/
    seccomp_t seccomp;

    /*
      38. 用于 copy_process 函数使用 CLONE_PARENT 标记时
    ,*/
    u32 parent_exec_id;
    u32 self_exec_id;

    /*
      39. alloc_lock
      用于保护资源分配或释放的自旋锁
    ,*/
    spinlock_t alloc_lock;

    /*
      40. 中断
    ,*/
  #ifdef CONFIG_GENERIC_HARDIRQS
    struct irqaction *irqaction;
  #endif
  #ifdef CONFIG_TRACE_IRQFLAGS
    unsigned int irq_events;
    int hardirqs_enabled;
    unsigned long hardirq_enable_ip;
    unsigned int hardirq_enable_event;
    unsigned long hardirq_disable_ip;
    unsigned int hardirq_disable_event;
    int softirqs_enabled;
    unsigned long softirq_disable_ip;
    unsigned int softirq_disable_event;
    unsigned long softirq_enable_ip;
    unsigned int softirq_enable_event;
    int hardirq_context;
    int softirq_context;
  #endif

    /*
      41. pi_lock
      task_rq_lock 函数所使用的锁
    ,*/
    spinlock_t pi_lock;

  #ifdef CONFIG_RT_MUTEXES
    /*
      42. 基于 PI 协议的等待互斥锁，其中 PI 指的是 priority inheritance/9 优先级继承)
    ,*/
    struct plist_head pi_waiters;
    struct rt_mutex_waiter *pi_blocked_on;
  #endif

  #ifdef CONFIG_DEBUG_MUTEXES
    /*
      43. blocked_on
      死锁检测
    ,*/
    struct mutex_waiter *blocked_on;
  #endif

    /*
      44. lockdep，
    ,*/
  #ifdef CONFIG_LOCKDEP
  # define MAX_LOCK_DEPTH 48UL
    u64 curr_chain_key;
    int lockdep_depth;
    unsigned int lockdep_recursion;
    struct held_lock held_locks[MAX_LOCK_DEPTH];
    gfp_t lockdep_reclaim_gfp;
  #endif

    /*
      45. journal_info
      JFS 文件系统
    ,*/
    void *journal_info;

    /*
      46. 块设备链表
    ,*/
    struct bio *bio_list, **bio_tail;

    /*
      47. reclaim_state
      内存回收
    ,*/
    struct reclaim_state *reclaim_state;

    /*
      48. backing_dev_info
      存放块设备 I/O 数据流量信息
    ,*/
    struct backing_dev_info *backing_dev_info;

    /*
      49. io_context
      I/O 调度器所使用的信息
    ,*/
    struct io_context *io_context;

    /*
      50. CPUSET 功能
    ,*/
  #ifdef CONFIG_CPUSETS
    nodemask_t mems_allowed;
    int cpuset_mem_spread_rotor;
  #endif

    /*
      51. Control Groups
    ,*/
  #ifdef CONFIG_CGROUPS
    struct css_set *cgroups;
    struct list_head cg_list;
  #endif

    /*
      52. robust_list
      futex 同步机制
    ,*/
  #ifdef CONFIG_FUTEX
    struct robust_list_head __user *robust_list;
  #ifdef CONFIG_COMPAT
    struct compat_robust_list_head __user *compat_robust_list;
  #endif
    struct list_head pi_state_list;
    struct futex_pi_state *pi_state_cache;
  #endif
  #ifdef CONFIG_PERF_EVENTS
    struct perf_event_context *perf_event_ctxp;
    struct mutex perf_event_mutex;
    struct list_head perf_event_list;
  #endif

    /*
      53. 非一致内存访问(NUMA  Non-Uniform Memory Access)
    ,*/
  #ifdef CONFIG_NUMA
    struct mempolicy *mempolicy;    /* Protected by alloc_lock */
    short il_next;
  #endif

    /*
      54. fs_excl
      文件系统互斥资源
    ,*/
    atomic_t fs_excl;

    /*
      55. rcu
      RCU 链表
    ,*/
    struct rcu_head rcu;

    /*
      56. splice_pipe
      管道
    ,*/
    struct pipe_inode_info *splice_pipe;

    /*
      57. delays
      延迟计数
    ,*/
  #ifdef    CONFIG_TASK_DELAY_ACCT
    struct task_delay_info *delays;
  #endif

    /*
      58. make_it_fail
      fault injection
    ,*/
  #ifdef CONFIG_FAULT_INJECTION
    int make_it_fail;
  #endif

    /*
      59. dirties
      FLoating proportions
    ,*/
    struct prop_local_single dirties;

    /*
      60. Infrastructure for displayinglatency
    ,*/
  #ifdef CONFIG_LATENCYTOP
    int latency_record_count;
    struct latency_record latency_record[LT_SAVECOUNT];
  #endif

    /*
      61. time slack values，常用于 poll 和 select 函数
    ,*/
    unsigned long timer_slack_ns;
    unsigned long default_timer_slack_ns;

    /*
      62. scm_work_list
      socket 控制消息(control message)
    ,*/
    struct list_head    *scm_work_list;

    /*
      63. ftrace 跟踪器
    ,*/
  #ifdef CONFIG_FUNCTION_GRAPH_TRACER
    int curr_ret_stack;
    struct ftrace_ret_stack    *ret_stack;
    unsigned long long ftrace_timestamp;
    atomic_t trace_overrun;
    atomic_t tracing_graph_pause;
  #endif
  #ifdef CONFIG_TRACING
    unsigned long trace;
    unsigned long trace_recursion;
  #endif
  };
#+END_SRC


* Select, Poll, Epoll 区别

每次调用 select 和 poll 都需要把文件描述符集合复制到内核当中, 可能是潜在
几百 KB 的开销, 同时返回时候会线性搜索检测的文件描述符

Epoll 创建时候会在内核分配一颗红黑树来保存检测的文件描述符, 因此没有调用开销.
同时在内核中断里为每一个文件描述符注册了一个回调函数, 把就绪的文件描述符加入一个
ready list 当中.

* 历史
  Multis -> Unics(汇编) -> Unix(C) -> BSD(Unix 分支)/System V(Official)
  -> Minix(Mini unix,Unix-like) -> Linux


* 进程
  内核把进程存放在一个双向循环链表, 称作任务队列(task list).

  2.6 以后, task_struct 不再直接放入内核栈, 而是在内核栈的栈底或者栈顶, 创建一个新的结构 thread_info.

#+BEGIN_SRC c
  struct thread_info {
    struct pcb_struct pcb;    /* palcode state */

    struct task_struct  *task;    /* main task structure */
    unsigned int    flags;    /* low level flags */
    unsigned int    ieee_state; /* see fpu.h */

    struct exec_domain  *exec_domain; /* execution domain */
    mm_segment_t    addr_limit; /* thread address space */
    unsigned    cpu;    /* current CPU */
    int     preempt_count; /* 0 => preemptable, <0 => BUG */

    int bpt_nsaved;
    unsigned long bpt_addr[2];    /* breakpoint handling  */
    unsigned int bpt_insn[2];

    struct restart_block  restart_block;
  };

#+END_SRC

其中的 task 指向该任务实际 task_struct 的指针.

内核查看 task_struct 过程中, 先要调用 current 宏得到线程内核栈, 然后调用 current_thread_info()
计算 thread_info 的偏移,最后从 thread_info 中的 task 得到 task_struct.

** 进程状态
   + TASK_RUNNING: 进程正在执行或者在 run_queue 中等待执行. 也是进程在用户空间中执行的唯一可能状态.
   + TASK_INTERRUPTIBLE: 进程正在睡眠(阻塞), 位于某个 wait_queue. 一旦睡眠条件解除, 内核会把进程设置为 TASK_RUNNING.
     处于此状态的进程也会因为接收到信号而提前被唤醒并随时准备投入运行.
   + TASK_UNINTERRUPTIBLE: 同上, 但处于此状态的任务对信号不做响应, 只能由内核唤醒, 例如 wake_up().
   + TASK_ZOMBIE: 进程已经终止, 但父进程还没有执行 wait()系统调用, 终止进程的信息也还没有回收.
   + TASK_STOPPED: 进程此时处于暂停状态来接受某个特殊处理. 通常进程接收到 SIGSTOP, SIGTSTP, SIGTTIN 或 SIGTTOU
     信号后就处于这种状态. 例如正接受调试的进程.
   + TASK_SWAPPING: 换入/换出

*** 设置当前进程状态.
     内核使用 set_task_state(task, state)来调整某个进程的状态.

     
** 进程创建  
   Unix 的进程创建分为两个阶段, fork()和 exec().
   
   fork()复制当前进程来创建一个子进程, 两者区别仅在于 PID, PPID, 和某些资源和统计量(例如, 挂起的信号).
   exec()复制读取可执行文件并将其载入地址空间开始运行.

*** 写时拷贝(copy-on-write)
    fork()并不复制整个今晨地址空间,而是让父子进程共享同一个拷贝, 因此实际开销就是复制父进程的页表以及给子进程
    创建唯一的进程描述符.

    资源的复制只有在需要写入的时候才进行,在此之前,只是以只读方式共享.
    
*** fork()
    linux 通过 clone()系统调用实现 fork(). 这个调用通过一系列的参数标志来指名父子进程需要共享的资源.

    然后 clone()去调用 do_fork(), do_fork()完成了创建的大部分工作, 该函数调用 copy_process(), 然后让
    进程开始运行.

    copy_process()完成了这些工作:
    + 调用 dup_task_struct()为新进程创建一个内核栈, thread_info 结构和 task_struct 结构, 这些值和父进程
      一模一样, 此时子进程和父进程的描述符是完全相同的.
    + 检查并确保新创建这个子进程后, 当前用户所拥有的进程数目没有超过给它分配的资源的限制.
    + 子进程着手是自己和父进程区别开来, 进程描述符许多成员都要被清零或设为初始值. task_struct 的大多数数据
      未被修改.
    + 子进程状态设为 TASK_UNINTERRUPTIBLE, 确保它不会运行.
    + copy_process()调用 copy_flags()以更新 task_struct 的 flags 成员.
    + 调用 alloc_pid()为新进程分配一个有效的 PID.
    + 根据传递给 clone()的参数标志, copy_process()拷贝或共享打开的文件, 文件系统信息, 信号处理函数, 进程地址空间
      和命名空间. 一般情况下, 这些资源会给父进程的所有子线程共享.
    + 最后, copy_process()做扫尾工作并返回一个指向子进程的指针.


** 创建线程
   线程的创建和普通进程的创建类似, 只不过在调用 clone()时候需要传递一些参数标志来指明需要共享的资源.

   clone(CLONE_VM | CLONE_FS | CLONE_FILES | CONE_SIGHAND, 0).

   上面的代码结果和调用 fork()差不多, 只是父子共享地址空间, 文件系统资源, 文件描述符和信号处理程序.

** 进程终结
   进程通过调用系统调用 exit()来终结, 终结的大部分靠 do_exit()完成.

   do_exit()完成以下工作.

   1. 把 task_struct 的 flags 设置为 PF_EXITING
   2. 调用 del_timer_sync()删除任一内核定时器.
   3. 调用 exit_mm()函数释放进程占用的 mm_struct, 如果没有别的进程共享它们, 就彻底释放它们.
   4. 接下来调用 sem_exit()函数, 如果进程排队等候 IPC 信号, 它则离开队列.
   5. 调用 exit_files()和 exit_fs(), 分别递减文件描述符, 文件系统数据的引用计数, 如果某个引用计数
      降为 0, 代表没有进程在使用相应资源, 释放对应资源.
   6. 接着把放在 task_struct 的 exit_code 成员中的任务退出代码置为由 exit()提供的退出代码,
      或者去完成任何内核机制规定的退出动作.
   7. 调用 exit_notify()向父进程发送信号, 给子进程寻找养父, 养父为线程组的其他线程或者为 init 进程.
      并把 exit_state 设为 EXIT_ZOMBIE.
   8. do_exit()调用 schedule()切换到新的进程. 因为处于 EXIT_ZOMBIE 的进程不会被调度, 所以
      这是进程执行的最后一段代码. do_exit()永不返回.

   至此, 与进程相关的资源都被释放掉了(假设该进程是唯一使用者), 进程不可运行(实际也没有地址空间给它运行)并处于
   EXIT_ZOMBIE 退出状态. 它占用的所有内存就是内核栈, thread_info 结构和 task_struct 结构. 此时进程存在的
   唯一目的就是向它的父进程提供信息. 父进程检索到信息后, 或者通知内核那是无关的信息后, 由进程持有的剩余内存被释放,
   归还给系统使用.

   
*** 删除进程描述符
    父进程通过 wait()系统调用收集其后代的信息.

    wait()函数族: 挂起调用它的进程, 直到其中的一个子进程退出, 此时函数会返回该子进程的 PID. 此外,调用该函数时提供的指针会包含子函数退出时
    的退出代码.

  
*** 孤儿进程
    如果父进程在子进程之前退出了, 必须有机制来保证子进程能找到一个新的父亲, 否则成为孤儿的进程永远处于僵死状态, 白白耗费内存.
    
    解决方法是给子进程在当前线程组内找一个线程组内作为父亲, 如果找不到, 就让 init 作为他们的父进程.

* 进程调度 
** 进程优先级
   Linux 采用了两种不同的优先级范围.

   第一种是用 nice 值, [-20, 19], 默认 0. nice 越高, 获得的 CPU 时间越少. 不同的 Unix 系统对 nice 运用方式有所不同, Mac OS X, 进程的 nice
   决定分配给进程时间片的绝对数值, linux 中, nice 代表时间片的比例.

   第二种是实时优先级, 默认变化范围[0, 99]. 与 nice 相反, 实时优先级数值越高, 进程优先级越高. 任何实时进程的优先级都高于普通进程.
   也就是实时优先级和 nice 优先级处于互不相交的两个范畴.

   Linux 的 CFS 调度器并没有直接分配时间片给进程, 它将处理器的使用比例划分给了进程. 这种情况下, 进程所获得的处理器时间其实是和系统负载密切相关.

   这个比例进一步还会收进程 nice 值的影响, nice 作为权重将调整进程所使用的 CPU 时间比. 具有高 nice 值的进程会被赋予低权重, 低 nice 值的进程会被赋予高权重.

   Linux 使用 CFS 调度器, 进程抢占时机取决于新的可运行进程消耗了多少处理器时间比, 如果消耗的使用比例比当前进程小, 则新进程立刻投入运行, 抢占当前进程.

** 调度器类   
   Linux 调度器是以模块方式提供的, 目的是运行不同类型的进程可以有针对性地选择调度算法.

   这种模块化结构被称为调度器类(scheduler classes), 它允许多种不同的可动态添加的调度算法并存, 调度属于自己范畴的进程.

   每个调度器有一个优先级, 内核会按照优先级顺序遍历调度器, 拥有一个可执行进程的最高优先级的调度器类胜出, 选择执行那一个线程.

   完全公平调度(CFS)是一个针对普通进程的调度类, linux 中称为 SCHED_NORMAL.
   
** 公平调度
   CFS 出发点基于一个简单的理念: 每个进程将能获得 1/n 的处理器时间, n 指可运行进程的数量.

   CFS 在所有可运行进程总数基础上计算出某个进程应该运行多久, 而不是依靠 nice 值计算时间片. nice 值在 CFS 中用作进程获得处理器运行比的权重.

   CFS 使用 targeted latency 作为调度周期来计算 timeslice, latency 越小, 越接近完美多任务.

   CFS 使用 minimum granularity 来表示 timeslice 的最小值, 这个值越小, 会加重 CPU 切换进程的负载.

   总结: 任何进程获得的 CPU 时间是由它自己和其他所有可运行进程 nice 值的相对差值决定的. nice 值对时间片的作用不再是算数加权, 而是几何加权.

   
** 时间记账
   所有调度器都必须对进程运行时间做记账.
   
   CFS 使用调度器实体结构来追踪进程运行记账:
   
#+BEGIN_SRC c
  struct sched_entity {
    struct load_weight  load;   /* for load-balancing */
    struct rb_node    run_node;
    struct list_head  group_node;
    unsigned int    on_rq;

    u64     exec_start;
    u64     sum_exec_runtime;
    u64     vruntime;
    u64     prev_sum_exec_runtime;

    u64     nr_migrations;

  #ifdef CONFIG_SCHEDSTATS
    struct sched_statistics statistics;
  #endif

  #ifdef CONFIG_FAIR_GROUP_SCHED
    struct sched_entity *parent;
    /* rq on which this entity is (to be) queued: */
    struct cfs_rq   *cfs_rq;
    /* rq "owned" by this entity/group: */
    struct cfs_rq   *my_q;
  #endif
  };
#+END_SRC

vruntime 变量存放进程的虚拟运行时间, 该运行时间的计算是经过了所有可运行进程总数的标准化. 虚拟时间以 ns 为单位,
所以 vruntime 和定时器节拍不再相关.

CFS 使用了 vruntime 变量来记录一个程序到底运行了多长时间以及它应该再运行多久.

#+BEGIN_SRC c
  static void update_curr(struct cfs_rq *cfs_rq)
  {
    struct sched_entity *curr = cfs_rq->curr;
    u64 now = rq_of(cfs_rq)->clock_task;
    unsigned long delta_exec;

    if (unlikely(!curr))
      return;

    /*
     ,* Get the amount of time the current task was running
     ,* since the last time we changed load (this cannot
     ,* overflow on 32 bits):
     ,*/
    delta_exec = (unsigned long)(now - curr->exec_start);
    if (!delta_exec)
      return;

    __update_curr(cfs_rq, curr, delta_exec);
    curr->exec_start = now;

    if (entity_is_task(curr)) {
      struct task_struct *curtask = task_of(curr);

      trace_sched_stat_runtime(curtask, delta_exec, curr->vruntime);
      cpuacct_charge(curtask, delta_exec);
      account_group_exec_runtime(curtask, delta_exec);
    }
  }
#+END_SRC

update_curr()计算了当前进程的执行时间, 并且将其存放在变量 delta_exec 中. 然后它又将运行时间传递给了__update_curr(), 
又后者再根据当前可运行进程总数对运行时间进行加权计算, 最终将权重值与当前运行进程的 vruntime 相加.

#+BEGIN_SRC c
  /*
   ,* Update the current task's runtime statistics. Skip current tasks that
   ,* are not in our scheduling class.
   ,*/
  static inline void
  __update_curr(struct cfs_rq *cfs_rq, struct sched_entity *curr,
                unsigned long delta_exec)
  {
    unsigned long delta_exec_weighted;

    schedstat_set(curr->statistics.exec_max,
                  max((u64)delta_exec, curr->statistics.exec_max));

    curr->sum_exec_runtime += delta_exec;
    schedstat_add(cfs_rq, exec_clock, delta_exec);
    delta_exec_weighted = calc_delta_fair(delta_exec, curr);

    curr->vruntime += delta_exec_weighted;
    update_min_vruntime(cfs_rq);

  #if defined CONFIG_SMP && defined CONFIG_FAIR_GROUP_SCHED
    cfs_rq->load_unacc_exec_time += delta_exec;
  #endif
  }
#+END_SRC


update_curr()是有系统定时器周期性调用的, 因此无论进程处于可运行, 还是被堵塞, vruntime 可以准确的测量给定进程的运行时间,
而且可知道谁应该是下一个被运行的进程.

** 进程选择
   CFS 调度算法的核心, 选择具有最小的 vruntime 的 task.

   CFS 使用红黑树来组织可运行进程队列, 并利用其迅速找到最小 vruntime 值的进程.

   在 Linux 值里面, 红黑树被称为 rbtree, 自平衡二叉树.

*** 挑选下一个任务
    假设有一个红黑树存储了系统中所有可运行进程. 其节点的键值便是可运行进程的 vruntime.
    
    CFS 调度器选取待运行的下一个进程, 是所有进程中 vruntime 最小的那个, 它对应的是树中最左侧的叶子节点.

    CFS 的进程选择算法可简单总结在"运行 rbtree 树中最左边叶子节点代表的进程".

    实现这一个过程的函数是__pick_next_entity()

    #+BEGIN_SRC c
      static struct sched_entity *__pick_first_entity(struct cfs_rq *cfs_rq)
      {
        struct rb_node *left = cfs_rq->rb_leftmost;

        if (!left)
          return NULL;

        return rb_entry(left, struct sched_entity, run_node);
      }

      static struct sched_entity *__pick_next_entity(struct sched_entity *se)
      {
        struct rb_node *next = rb_next(&se->run_node);

        if (!next)
          return NULL;

        return rb_entry(next, struct sched_entity, run_node);
      }
    #+END_SRC

    实际上 linux 把最左叶子点点缓存在一个 rb_leftmost 字段中, 因此可直接调用.


*** 向树中加入进程
    CFS 把进程加入 rbtree 中, 以及缓存最左叶子节点的过程发生在进程变为可运行状态(被唤醒), 或者是通过 fork()调用第一次创建进程时候.
    enqueue_entity()实现了这个过程.

    #+BEGIN_SRC c
      static void
      enqueue_entity(struct cfs_rq *cfs_rq, struct sched_entity *se, int flags)
      {
        /*
         ,* Update the normalized vruntime before updating min_vruntime
         ,* through callig update_curr().
         ,*/
        if (!(flags & ENQUEUE_WAKEUP) || (flags & ENQUEUE_WAKING))
          se->vruntime += cfs_rq->min_vruntime;

        /*
         ,* Update run-time statistics of the 'current'.
         ,*/
        update_curr(cfs_rq);
        update_cfs_load(cfs_rq, 0);
        account_entity_enqueue(cfs_rq, se);
        update_cfs_shares(cfs_rq);

        if (flags & ENQUEUE_WAKEUP) {
          place_entity(cfs_rq, se, 0);
          enqueue_sleeper(cfs_rq, se);
        }

        update_stats_enqueue(cfs_rq, se);
        check_spread(cfs_rq, se);
        if (se != cfs_rq->curr)
          __enqueue_entity(cfs_rq, se);
        se->on_rq = 1;

        if (cfs_rq->nr_running == 1)
          list_add_leaf_cfs_rq(cfs_rq);
      }
    #+END_SRC

    该函数更新运行时间和其他一些统计数据, 然后调用__enqueue_entity()进行插入操作.

    #+BEGIN_SRC c
      /*
       ,* Enqueue an entity into the rb-tree:
       ,*/
      static void __enqueue_entity(struct cfs_rq *cfs_rq, struct sched_entity *se)
      {
        struct rb_node **link = &cfs_rq->tasks_timeline.rb_node;
        struct rb_node *parent = NULL;
        struct sched_entity *entry;
        s64 key = entity_key(cfs_rq, se);
        int leftmost = 1;

        /*
         ,* Find the right place in the rbtree:
         ,*/
        while (*link) {
          parent = *link;
          entry = rb_entry(parent, struct sched_entity, run_node);
          /*
           ,* We dont care about collisions. Nodes with
           ,* the same key stay together.
           ,*/
          if (key < entity_key(cfs_rq, entry)) {
            link = &parent->rb_left;
          } else {
            link = &parent->rb_right;
            leftmost = 0;
          }
        }

        /*
         ,* Maintain a cache of leftmost tree entries (it is frequently
         ,* used):
         ,*/
        if (leftmost)
          cfs_rq->rb_leftmost = &se->run_node;

        rb_link_node(&se->run_node, parent, link);
        rb_insert_color(&se->run_node, &cfs_rq->tasks_timeline);
      }
    #+END_SRC


*** 从树中删除进程
    从 rbtree 中删除进程, 发生在进程堵塞或者终止时.

    #+BEGIN_SRC c
      static void
      dequeue_entity(struct cfs_rq *cfs_rq, struct sched_entity *se, int flags)
      {
        /*
         ,* Update run-time statistics of the 'current'.
         ,*/
        update_curr(cfs_rq);

        update_stats_dequeue(cfs_rq, se);
        if (flags & DEQUEUE_SLEEP) {
      #ifdef CONFIG_SCHEDSTATS
          if (entity_is_task(se)) {
            struct task_struct *tsk = task_of(se);

            if (tsk->state & TASK_INTERRUPTIBLE)
              se->statistics.sleep_start = rq_of(cfs_rq)->clock;
            if (tsk->state & TASK_UNINTERRUPTIBLE)
              se->statistics.block_start = rq_of(cfs_rq)->clock;
          }
      #endif
        }

        clear_buddies(cfs_rq, se);

        if (se != cfs_rq->curr)
          __dequeue_entity(cfs_rq, se);
        se->on_rq = 0;
        update_cfs_load(cfs_rq, 0);
        account_entity_dequeue(cfs_rq, se);
        update_min_vruntime(cfs_rq);
        update_cfs_shares(cfs_rq);

        /*
         ,* Normalize the entity after updating the min_vruntime because the
         ,* update can refer to the ->curr item and we need to reflect this
         ,* movement in our normalized position.
         ,*/
        if (!(flags & DEQUEUE_SLEEP))
          se->vruntime -= cfs_rq->min_vruntime;
      }
    #+END_SRC
    和红黑树添加进程一样, 实际工作是由辅助函数__dequeue_entity()完成.

    #+BEGIN_SRC c
      static void __dequeue_entity(struct cfs_rq *cfs_rq, struct sched_entity *se)
      {
        if (cfs_rq->rb_leftmost == &se->run_node) {
          struct rb_node *next_node;

          next_node = rb_next(&se->run_node);
          cfs_rq->rb_leftmost = next_node;
        }

        rb_erase(&se->run_node, &cfs_rq->tasks_timeline);
      }
    #+END_SRC

** 调度器入口
   进程调度的入口 schedule(), 它是内核其他部分用于进程调度器的入口, 选择哪个进程可以运行, 何时将其投入运行.

   schedule()通常需要和一个具体的调度类相关联, 也就是说, 它会找到一个最高优先级的调度类---后者通常需要有自己的
   可运行队列, 然后问后者谁才是下一个该运行的进程. 该函数唯一重要的事情是, 它会调用 pick_next_task()中.
   pick_next_task()会以优先级为序, 从高到低, 依次检查每一个调度类, 并且从最高优先级的调度类中, 选择最高优先级的进程.

   #+BEGIN_SRC c
     /*
      ,* Pick up the highest-prio task:
      ,*/
     static inline struct task_struct *
     pick_next_task(struct rq *rq)
     {
       const struct sched_class *class;
       struct task_struct *p;

       /*
        ,* Optimization: we know that if all tasks are in
        ,* the fair class we can call that function directly:
        ,*/
       if (likely(rq->nr_running == rq->cfs.nr_running)) {
         p = fair_sched_class.pick_next_task(rq);
         if (likely(p))
           return p;
       }

       for_each_class(class) {
         p = class->pick_next_task(rq);
         if (p)
           return p;
       }

       BUG(); /* the idle class will always have a runnable task */
     }
   #+END_SRC

** 睡眠和唤醒
   睡眠: 进程把自己标记成休眠状态, 从可执行红黑树中移除, 放入等待队列, 然后调用 schedule()选择和执行其他进程.

   休眠状态: TASK_INTERRUPTIBLE 和 TASK_UNINTERRUPTIBLE. 他们唯一的区别是后者会忽略信号, 而前者接收到信号, 会被提前唤醒并响应信号.

   唤醒: 进程被设为可执行状态, 然后从等待队列移到可执行红黑树中.
   
*** 等待队列
    休眠通过等待队列来处理. 等待队列是由等待某些时间发生的进程组成的简单链表. 内核用 wake_queue_head_t 来代表等待队列.

    进程通过执行下面几个步骤将自己加入到一个等待队列中.

    1. 调用 DEFINE_WAIT()创建一个等待队列的宏
    2. 调用 add_wait_queue()把自己加入到队列中. 该队列会在进程等待的条件满足时唤醒它. 当然我们必须在其他地方撰写相关代码, 在事件发生时, 对等待队列执行 wake_up()操作.
    3. 调用 prepare_to_wait()方法把进程 state 变更为 TASK_INTERRUPTIBLE 或者 TASK_UNINTERRUPTIBLE. 该函数如果有必要会将进程加回到等待队列, 这是接下来的循环遍历所需要的.
    4. 如果 state 设置为 TASK_INTERRUPTIBLE, 则用信号唤醒进程. 这就是所谓的伪唤醒(因为不是由于事件发生而唤醒), 因此检查并处理信号.
    5. 当进程被唤醒时候, 它会再次检查条件是否为真, 如果是, 它就退出循环, 如果不是, 它再次调用 schedule()并一直重复.
    6. 当条件满足时候, 进程把 state 设置为 TASK_RUNNING 并调用 finish_wait()方法把自己移出等待队列.

       #+BEGIN_SRC c
         /* ‘q’ is the wait queue we wish to sleep on */
         DEFINE_WAIT(wait);
         add_wait_queue(q, &wait);
         while (!condition) {    /* condition is the event that we are waiting for */
           prepare_to_wait(&q, &wait, TASK_INTERRUPTIBLE);
           if (signal_pending(current))
             /* handle signal */
             schedule();
          }
         finish_wait(&q, &wait);
       #+END_SRC

*** 唤醒
    唤醒操作通过函数 wake_up()进行, 它会唤醒指定的等待队列上的所有进程. 它调用函数 try_to_wake_up(), 该函数负责把进程设置为 TASK_RUNNING 状态, 调用 enqueue_task()将此进程
    放入红黑树中. 如果被唤醒的进程优先级比当前正在执行的进程的优先级高, 还要设置 need_resched 标志. 
    
    通常哪段代码促使等待条件达成, 他就要负责随后调用 wake_up()函数, 举例来说, 当磁盘数据到来时, VFS 就要负责对等待队列调用 wake_up(), 以唤醒队列中等待这些数据的进程.

** 抢占和上下文切换
   上下文切换, 有 context_switch()负责处理.

   每当一个新的进程被选出来准备投入运行时, schedule()就会调用该函数.

   它完成了两项基本工作:
   + 调用声明在<asm/mmu_context.h>中的 switch_mm(), 该函数负责把虚拟内存从上一个进程映射切换到新进程中, 即是切换新进程的虚拟内存.
   + 调用声明在 <asm/system.h>中的 switch_to(), 该函数负责从上一个进程的处理器状态切换到新进程的处理器状态. 这包括保存, 回复栈信息和寄存器信息, 还有其他任何与体系结构相关的状态信息, 都必须以每个进程为对象进行管理和保存.

     内核必须知道什么时候调用 schedule(). 内核提供了一个 need_resched 标志表明是否需要重新执行一次调度. 当某个进程应该被抢占时, scheduler_tick()就会设置这个标志, 当一个优先级高的进程进入可执行状态的时候, try_to_wake_up()
     也会设置这个标志. 内核检查该标志, 如果被设置, 则调用 schedule()来切换进程. 该标志对于内核来讲是一个信息, 它表示有其他进程应该被运行, 要尽快调度程序.

   + set_tsk_need_resched(): 设置指定进程中的 need_resched 标志
   + clear_tsk_need_resched(): 清除指定进程中的 need_resched 标志.
   + need_resched(): 返回 need_resched 标志的值.

     返回用户空间和中断返回时候, 内核也会检查 need_resched 标志. 如果已被设置, 内核会在继续执行之前调用 schedule().

     每一个进程都包含一个 need_resched 标志, 这是因为访问进程描述符内的数值比访问全局变量快(因为 current 宏速度很快并且描述符通常都在高速缓存中).

     Linux2.6 中, need_reshed 被移到 thread_info 结构体里面.


*** 用户抢占
    内核即将返回用户控件时候, 如果 need_resched 被设置, 会调用 schedule(), 此时发生用户抢占.

    用户抢占在以下情况时发生:
    + 从系统调用返回用户空间时.
    + 从中断处理程序返回用户空间时.

*** 内核抢占
    Linux 完美地支持内核抢占.

    在一个不支持内核抢占的内核中, 内核代码可以一直执行, 到他完成为止. 也就是说, 调度程度没有办法在一个内核级的任务正在执行的时候重新调度---内核中的各任务是以协作方式调度的, 不具备抢占性.

    在 Linux 2.6 中,只要重新调度是安全的, 内核可以在任何时间抢占正在执行的任务. 只要没有持有锁, 内核就可以进行抢占.

    由于内核是支持 SMP, 所以, 只要没有持有锁, 正在执行的代码就是可重新导入的, 也就是可以抢占的.

    为了支持内核抢占, 就是为每个进程的 thread_info 引入 preempt_count 计数器. 持有锁时候加 1, 释放锁时候减 1. 当数值为 0 时候, 内核就可执行抢占.

    从中断返回内核空间的时候, 内核会检查 need_resched 和 preempt_count 的值. 如果 need_resched 被设置, preempt_count 值为 0, 这说明有一个更为重要单位任务需要执行并且可以安全抢占.
    此时, 调度程序就会被调用. 如果 preempt_count 不为 0, 说明当前任务持有锁, 所以抢占是不安全的. 这时, 内核就会像通常那样直接从中断返回到当前执行进程. 如果当前进程持有的所有锁都被释放了, preempt_count 就会重新为 0.
    此时, 释放锁的代码会检查 need_reshed 是否被设置. 如果是的话,就会调用调度程序.

    如果内核中的进程被阻塞, 或者显式调用了 schedule(), 内核抢占也会显示发生. 因为这种抢占总是安全的.

    内核抢占会发生在:
    + 中断处理程序正在执行, 且返回内核空间之前.
    + 内核代码在一次具有可抢占性时候.
    + 内核中的任务显式调用 schedule().
    + 内核中的任务阻塞.

** 实时调度策略
   Linux 提供了两种实时调度策略: SCHED_FIFO 和 SCHED_RR. 而普通的, 非实时的调度策略是 SCHED_NORMAL. 借助调度类的框架, 这些实时策略并不被 CFS 调度器管理, 而是被一个特殊的实时调度器管理.

   SCHED_FIFO 实现了一个简单的, 先入先出的调度算法: 它不使用时间片. 处于可运行状态的 SCHED_FIFO 级的进程回避任何 SCHED_NORMAL 级的进程优先得到调度.
   一旦一个 SCHED_FIFO 进程处于可执行状态, 就会一直执行, 直到它自己受阻塞或显式释放 CPU; 它不基于时间片, 可以一直执行下去. 只有更高优先级的 SCHED_FIFO 或者 SCHED_RR 才能抢占 SCHED_FIFO 任务.
   
   SCHED_RR 和 SCHED_FIFO 大体相同, 只是 SCHED_RR 级进程在耗尽事先分配给它的时间后就不能再继续执行了. 也就是说, SCHED_RR 就是带有时间片的 SCHED_FIFO.

   两种实施算法实现的都是静态优先级, 内核不为实时进程计算动态优先级.

*** 放弃处理器时间
    Linux 通过 sched_yield()系统调用, 使进程能主动放弃 CPU 时间, 它是通过将进程从活动队列中移到过期队列中实现的.

* Linux 内存管理
  内存管理单元(MMU, 管理内存并把虚拟地址转换成物理地址的硬件), 通常以页为最小单位进行处理.

  32 位体系结构支持 4KB 的页, 64 为体系结构一般还会支持 8KB 的页.

  内核用 struct page 结构表示系统中的物理页.

  #+BEGIN_SRC c
    /*
     ,* Each physical page in the system has a struct page associated with
     ,* it to keep track of whatever it is we are using the page for at the
     ,* moment. Note that we have no way to track which tasks are using
     ,* a page, though if it is a pagecache page, rmap structures can tell us
     ,* who is mapping it.
     ,*/
    struct page {
      unsigned long flags;    /* Atomic flags, some possibly
               ,* updated asynchronously */
      atomic_t _count;    /* Usage count, see below. */
      union {
        atomic_t _mapcount; /* Count of ptes mapped in mms,
               ,* to show when page is mapped
               ,* & limit reverse map searches.
               ,*/
        struct {    /* SLUB */
          u16 inuse;
          u16 objects;
        };
      };
      union {
          struct {
        unsigned long private;    /* Mapping-private opaque data:
                 ,* usually used for buffer_heads
                 ,* if PagePrivate set; used for
                 ,* swp_entry_t if PageSwapCache;
                 ,* indicates order in the buddy
                 ,* system if PG_buddy is set.
                 ,*/
        struct address_space *mapping;  /* If low bit clear, points to
                 ,* inode address_space, or NULL.
                 ,* If page mapped as anonymous
                 ,* memory, low bit is set, and
                 ,* it points to anon_vma object:
                 ,* see PAGE_MAPPING_ANON below.
                 ,*/
          };
    #if USE_SPLIT_PTLOCKS
          spinlock_t ptl;
    #endif
          struct kmem_cache *slab;  /* SLUB: Pointer to slab */
          struct page *first_page;  /* Compound tail pages */
      };
      union {
        pgoff_t index;    /* Our offset within mapping. */
        void *freelist;   /* SLUB: freelist req. slab lock */
      };
      struct list_head lru;   /* Pageout list, eg. active_list
               ,* protected by zone->lru_lock !
               ,*/
      /*
       ,* On machines where all RAM is mapped into kernel address space,
       ,* we can simply calculate the virtual address. On machines with
       ,* highmem some memory is mapped into kernel virtual memory
       ,* dynamically, so we need a place to store that address.
       ,* Note that this field could be 16 bits on x86 ... ;)
       ,*
       ,* Architectures with slow multiplication can define
       ,* WANT_PAGE_VIRTUAL in asm/page.h
       ,*/
    #if defined(WANT_PAGE_VIRTUAL)
      void *virtual;      /* Kernel virtual address (NULL if
                 not kmapped, ie. highmem) */
    #endif /* WANT_PAGE_VIRTUAL */
    #ifdef CONFIG_WANT_PAGE_DEBUG_FLAGS
      unsigned long debug_flags;  /* Use atomic bitops on this */
    #endif

    #ifdef CONFIG_KMEMCHECK
      /*
       ,* kmemcheck wants to track the status of each byte in a page; this
       ,* is a pointer to such a status block. NULL if not tracked.
       ,*/
      void *shadow;
    #endif
    };
  #+END_SRC

  flags 字段用来存放页的状态, 包括页是不是脏的, 是不是被锁定在内存中. 每一位单独表示一种状态, 所以它至少可以同时
  表现出 32 种不同的状态.

  _count 字段存放了页的引用计数, 也就是这一页被引用了多少次, 当计数值变为-1 时, 说明内核没有使用这一页, 新的内存分配中
  可以使用这一页. 内核调用 page_count()函数进行检查, 该函数的唯一参数就是 page 结构体. page_count()返回 0 表示页空闲,
  返回一个正整数表示页在使用.
  
  virtual 字段表示该页的虚拟地址.

  系统中的每个物理页都要分配一个这样的结构体.

* 系统调用(syscall)  
** 系统调用程序
   用户空间的程序无法直接执行内核代码, 因为这意味着读写内核的地址空间, 系统的安全性和稳定性无法保证.

   因此应用程序需要一种机制通知内核, 让内核代替其执行系统调用.

   通知内核的机制靠软中断去实现: 通过引发一个异常来促使系统切换到内核态去执行异常处理程序, 此时的异常处理程序实际上就是系统调用处理程序.

   在 x86 系统上预定义的软中断是中断号 128, 通过 int $0x80 指令触发该中断. 这条指令会触发一个异常, 导致系统切换到内核态并执行 128 号
   异常处理程序, 而该程序正是系统调用处理程序. 这个程序名字叫做 system_call().

*** 指定恰当的系统调用
    仅仅陷入内核空间是不够的, 还必须把系统调用号一并传递给内核. 在 x86 上, 系统是通过 eax 寄存器.
    在陷入内核前, 用户空间就把相应系统调用所对应的号放入 eax 中. 一旦 system_call()开始执行后,
    就可以从 eax 中得到系统调用号.

    system_call()首先把系统调用号和 NR_syscalls 比较, 检查有效性. 如果大于等于它, 返回-ENOSYS. 否则, 执行相应的系统调用.

    各种系统调用是存放在一张系统调用表上, system_call()会到该表上检索对应的系统调用函数入口.

*** 参数传递
    有时候系统调用还需要传入参数, 这些参数一般也存储在寄存器当中.
    给用户空间的返回值也通过寄存器传递. x86 系统上, 存放在 eax 寄存器中.

    
** 系统调用的实现
   参数验证, 特别是指针.

   内核提供了两个函数来完成必须的检查和内核空间与用户空间之间数据的来回拷贝.
   向用户空间写数据, 内核提供了 copy_to_user().
   从用户空间读数据, 内核提供了 copy_from_user().

   当编写完一个系统调用后, 需要把它注册成一个正式的系统调用.
   1. 首先, 在系统调用表的最后加入一个表项, 从 0 开始, 系统调用在该表中的位置就是它的系统调用号.
   2. 对于所支持的各种体系架构, 系统调用号都必须定义于<asm/unistd.h>
   3. 把系统调用放入 kernel/ 目录下, 最后编译进入内核映像.
      
*** 用户空间调用系统调用
    Linux 本身提供了一组宏, 用于直接对系统调用进行访问, 它会设置好寄存器并调用指令, 这些宏是_syscalln(), 其中 n 是 0 到 6, 代表传递
    的参数个数. 每个宏都有 2+2xn 个参数. 第一个代表返回值类型, 第二个是系统调用的名称, 后面是参数的类型和名称.

* 内核同步方法

** 自旋锁
   等待自旋锁的线程会陷入忙等待, 循环等待锁被释放.
   等待信号量的线程会陷入睡眠, 而不是旋转.

   自旋锁可以用在中断处理程序中, 但获得锁之前, 首先要禁止本地中断(当前 CPU 上的中断请求), 否则其他中断处理程序会打断持有锁的内核代码, 有可能会试图去
   获得这个自旋锁. 这样一来会形成双重请求死锁.

** 读/写自旋锁

** 信号量
   Linux 中的信号量是一种睡眠锁, 如果一个任务试图获得一个不可用的信号量时, 信号量会将其推进一个等待队列, 让其睡眠.
   当持有的信号量可用时, 处于等待队列中的那个任务将被唤醒, 并获得信号量.

   + 信号量适用于锁会被长时间持有的情况.
   + 锁被短时间持有时, 信号量不太合适, 因为睡眠,维护等待队列以及唤醒所花费的开销可能比锁被占用的全部时间还要长.
   + 占有信号量时候不能占用自旋锁, 因为等待信号量可能会睡眠, 而持有自旋锁时不允许睡眠.

     Linux 通过 down()操作获得信号量, 当信号量小于零时候, 线程被放入等待队列, 置为 TASK_UNINTERRUPTIBLE, up()操作释放信号量.

     一般情况下 down_interruptible()更常用.

     down_trylock()函数, 信号量已被占用时, 返回非 0, 否则返回 0 而且让你成功获得信号量锁.
** 读/写信号量
** mutex 互斥体
   mutex 指任何可以睡眠的强制互斥锁, 比如使用计数为 1 的信号量.

   mutex 在内核中对应数据结构 mutex.
   + mutex_lock
   + mutex_unlock
   + mutex_trylock
   + mutex_is_locked
     
     mutex 的使用场景相对更加严格, 使用上优先级比信号量高.
** 顺序锁
   2.6 才引入的一种新型锁. 这种锁提供了一种很简单的机制, 用于读写共享数据. 实现这种锁主要依靠一个序列计数器, 当有疑义的数据被写入时, 
   会得到一个锁, 并且序列值会增加. 在读数据之前和之后, 序列号都被读取, 如果序列号相同, 说明读操作的过程中没有被写操作打断过.
   此外, 如果读取的序列号值是偶数, 说明写操作没有发生.(锁初值为 0, 写锁会使值变成奇数, 释放时候变成偶数.)

   seq 锁对写者更有利, 读者不影响写锁.


* 磁盘

  1. 寻道时间
  2. 旋转时间
     
     磁盘的读写基本单位是扇区, 是一个物理概念, 是 512 字节.

     操作系统的文件系统操作文件的最小单位是块, 是一个抽象概念.
     操作系统与内存打交道, 是以页的概念作为最小单位.
     
  磁盘顺序读取效率很高, 因为没有寻道时间, 只需要很少的旋转时间. 因此对于具有局部性的程序来说, 预读可以提高 I/O 效率.

  预读的长度一般为页的整倍数.

  linux 要求块的大小是 2 的 n 次方乘以扇区的大小, 内存页的大小大于等于块的大小, 大多数时候页大小等于块大小, 都是 4K, 即是 8 个扇区大小.

** 局部性原理
   当一个数据被用到时, 其附近的数据通常也会马上被使用.


* 数据库
  数据库设计者巧妙利用了磁盘预读原理, 将一个节点的大小设为一个页的大小, 这样每个节点只需要一次 I/O 就可以完全载入.

  B-Tree 一次检索最多需要 h-1 次 I/O(根节点常驻内存), 复杂度为 O(h)=O(logdN). 一般实际应用中, 度 d 是个非常大的数字,
  通常超过 100, 因此 h 非常小(通常不超过 3).

  因此, 用 B-Tree 作为索引结构的效率非常高.

  红黑树这种结构, h 明显深得多, 效率明显比 B-Tree 差得多.

** 存储引擎
   在 MySQL 中, 索引属于存储引擎级别的概念, 不同存储引擎对索引的实现方式是不同的.

*** MyISAM 索引实现
    每个叶节点的 data 域保存的是数据记录的地址.
    索引解锁的算法为首先按照 B+Tree 搜索算法搜索索引, 如果指定 Key 存在, 则取出其 data 域的值, 然后以 data 域的值为地址, 读取相应数据记录.

    MyISAM 这种索引方式也叫作非聚簇的, 这么称呼是为了与 InnoDB 的聚簇索引区分.
    
*** InnoDB 索引实现
    第一个重大区别是 InnoDB 的数据文件本身就是索引文件, 上文讨论的 MyISAM 索引文件和数据文件是分离的, 索引文件仅仅保存数据记录的地址.
    
    而在 InnoDB 中, 表数据文件本身就是按 B+Tree 组织的一个索引结构, 这棵树的叶节点 data 域保存了完整的数据记录. 因此 InnoDB 的表数据就是主索引.

    InnoDB 的所有辅助索引都引用 Primary Key 作为 data 域.

    聚簇索引这种实现使得按主键的搜索十分高效, 但是辅助索引需要检索两遍索引: 首先检索辅助索引取得主键, 然后用主键到主索引中检索获得记录.

** 索引使用策略及优化
   MySQL 的优化主要分为结构优化和查询优化.

** 索引选择性与前缀索引
   索引虽然加快了查询速度, 但索引文件本身需要消耗存储空间, 同时索引会加大插入,删除和修改记录的负担, 另外 MySQL 运行时候也要消耗资源维持索引, 因此索引不是越多越好.

** InnoDB 的主键选择与插入优化.
   在使用 InnoDB 存储引擎时, 如果没有特别的需要, 请使用一个与业务无关的自增字段作为主键.

   主要与 B+Tree 的插入操作有关, 如果使用自增主键, 每次插入新纪录, 记录会顺序添加到索引的最后位置.
   如果使用非自增主键, 由于每次主键的值近乎随机, 每次新纪录都会插入到现有的索引页的某个中间位置, MySQL 不得不为了将新纪录插到合适位置而移动数据, 缓存也要更新, 这增加了很多开销.
